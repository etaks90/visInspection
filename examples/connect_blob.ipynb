{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import os, datetime\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import io\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def upload_file_to_blob(blob_service_client, container_name, file_path, blob_name):\n",
    "    try:\n",
    "        # Create the container if it doesn't already exist\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        if not container_client.exists():\n",
    "            container_client = blob_service_client.create_container(container_name)\n",
    "\n",
    "        # Create a blob client using the local file name as the name for the blob\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "        # Upload the file\n",
    "        with open(file_path, \"rb\") as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "        print(\"File was uploaded successfully to Blob storage.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def get_blob_service_client(connection_string):\n",
    "    return BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "connection_string = os.getenv(\"CSTR__BLOB__VISINSP\")\n",
    "\n",
    "# Create the BlobServiceClient object which will be used to create a container client\n",
    "blob_service_client = get_blob_service_client(connection_string)\n",
    "\n",
    "container_name = \"image-uploads\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "    import tempfile\n",
    "    import tensorflow as tf\n",
    "    blob_client = blob_service_client.get_blob_client(container=\"config\", blob=\"trained_model.keras\")\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix='.keras', delete=True) as temp_file:\n",
    "        # Download the blob content\n",
    "        print(\"aaa\")\n",
    "        download_stream = blob_client.download_blob()\n",
    "        print(\"bbb\")\n",
    "        temp_file.write(download_stream.readall())\n",
    "        print(\"ccc\")\n",
    "        temp_file.flush()  # Ensure all data is written to disk\n",
    "        print(\"ddd\")\n",
    "        # Seek to the start of the file to ensure tf.keras can read it from the beginning\n",
    "        temp_file.seek(0)\n",
    "        print(\"eee\")\n",
    "        # Load the model using TensorFlow/Keras\n",
    "        model = tf.keras.models.load_model(temp_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary file manually\n",
    "temp_dir = tempfile.gettempdir()\n",
    "temp_file_path = os.path.join(temp_dir, \"temp_model.keras\")\n",
    "\n",
    "try:\n",
    "    # Download the blob to the temporary file\n",
    "    with open(temp_file_path, \"wb\") as temp_file:\n",
    "        download_stream = blob_client.download_blob()\n",
    "        temp_file.write(download_stream.readall())\n",
    "        temp_file.flush()\n",
    "\n",
    "    # Load the model using TensorFlow/Keras\n",
    "    model = tf.keras.models.load_model(temp_file_path)\n",
    "    print(\"Model loaded successfully\")\n",
    "finally:\n",
    "    # Clean up the temporary file\n",
    "    if os.path.exists(temp_file_path):\n",
    "        os.remove(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.keras', delete=True) as temp_file:\n",
    "    temp_file.write(b\"aaaaaaa\")\n",
    "    temp_file.seek(0)\n",
    "    b = temp_file.read()\n",
    "    print(temp_file.name)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 2:\n",
    "    file_path = r\"C:\\Users\\oliver.koehn\\Documents\\gitProjects\\qualityInspection\\.gitignore\"\n",
    "    blob_name = \"dummytest123\"\n",
    "    upload_file_to_blob(blob_service_client, container_name, file_path, blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPLOAD LOCAL FILE cast_ok_0_998.jpeg to BLOB AS cast_ok_0_998__20240531173844585901.jpeg\n",
      "fp_local: C:\\Users\\Rebekka\\gitProjects\\visInspection\\in\\samples\\cast_ok_0_998.jpeg\n",
      "fp_blob: 2024/05/31/cast_ok_0_998__20240531173844585901.jpeg\n",
      "File was uploaded successfully to Blob storage.\n"
     ]
    }
   ],
   "source": [
    "base_path_local_files = r\"C:\\Users\\Rebekka\\gitProjects\\visInspection\\in\\samples\"\n",
    "l__ok_images = [998]\n",
    "for n in l__ok_images:\n",
    "    fn_original = f\"cast_ok_0_{n}.jpeg\"\n",
    "    fn_blob = fn_original.replace(\".jpeg\", f\"__{datetime.datetime.now().strftime('%Y%m%d%H%M%S%f')}.jpeg\")\n",
    "    fp_local = os.path.join(base_path_local_files, fn_original)\n",
    "    fp_blob = f\"{datetime.datetime.now().strftime('%Y')}/{datetime.datetime.now().strftime('%m')}/{datetime.datetime.now().strftime('%d')}/{fn_blob}\"\n",
    "    print(f\"UPLOAD LOCAL FILE {fn_original} to BLOB AS {fn_blob}\")\n",
    "    print(f\"fp_local: {fp_local}\")\n",
    "    print(f\"fp_blob: {fp_blob}\")\n",
    "    upload_file_to_blob(blob_service_client, container_name, fp_local, fp_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_from_blob(blob_service_client, container_name, blob):\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob)\n",
    "    stream = blob_client.download_blob()\n",
    "    return Image.open(io.BytesIO(stream.readall())) # image.show()\n",
    "\n",
    "def format_image_for_model(image):\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((200, 200))\n",
    "    image_array = img_to_array(image)\n",
    "    image_array = image_array * (1./255)\n",
    "    return np.expand_dims(image_array, axis=0)\n",
    "\n",
    "def eval_img_from_blob(loaded_model, blob_service_client, container_name, blob):\n",
    "    image = read_image_from_blob(blob_service_client, container_name, blob)\n",
    "    img_array = format_image_for_model(image)\n",
    "    result = loaded_model.predict(img_array)\n",
    "    prob__ok = result[0][1]\n",
    "    #j__db = {\"FP__BLOB\" : blob, \"CONTAINER_NAME\" : container_name, \"PROBABILITY_OK\": prob__ok}\n",
    "\n",
    "    return prob__ok\n",
    "\n",
    "eval_img_from_blob(loaded_model, blob_service_client, container_name, \"2024/05/21/cast_ok_0_31__20240521155649383512.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvQualInsp311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
